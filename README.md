# Perceptrons and Kernel PCA

<p align="justify">This repository is really a culmination of two projects. 
</p>

<p align="justify">The first demonstrates the use of the Perceptron rule for machine learning to evaluate its efficacy as a classification algorithm relative to a logistic regression model in learning how to recognize whether a US college is private or public.
</p>

<p align="justify">The second demonstrates the effectiveness of Kernel PCA in classifying Fisherâ€™s Iris data as the species I. Setosa and others, evaluated using its K- means counterpart.
</p>

<p align="justify">The Perceptron rule is a simple machine learning algorithm for supervised learning used for binary classifications where the Perceptron learns a linear decision boundary to separate input observations for features into binary forms. It trains by updating estimates of the augmented vector for the hyperplane through vectorization and converging on the optimal weights.</p>

<p align="justify">Logistic regression models are also supervised learning models used for binary classification. It trains by using a training set of labels, and weights are calculated through maximum likelihood estimation, which can handle non-linear boundaries.
</p>

<p align="justify">Kernel PCA is a dimensionality reduction algorithm which computes the principal components of a dataset by using a kernel function in a higher-dimensional feature space, which allows it to identify non-linear relationships between features and produce greater separation.</p>

<p align="justify">Read a5.pdf for a detailed analysis and illustrations.</p>